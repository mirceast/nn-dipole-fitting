{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Using GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "from misc import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# First we should load the .mat file\n",
    "data_dir = \"C:/Users/Mircea/Google Drive/Data/nn-dipole-fitting/\"\n",
    "path_list = [each.replace(\"\\\\\",\"/\") for each in glob(data_dir + \"Dataset SNR*.mat\")]\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using\",torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data if not already in memory\n",
    "if \"data_train\" not in globals():\n",
    "    dataset = dataset_from_mat(path_list[-1])\n",
    "\n",
    "min_location = torch.from_numpy(dataset.data_train[\"min_location\"].T).to(device)\n",
    "max_location = torch.from_numpy(dataset.data_train[\"max_location\"].T).to(device)\n",
    "min_moment = torch.from_numpy(dataset.data_train[\"min_moment\"].T).to(device)\n",
    "max_moment = torch.from_numpy(dataset.data_train[\"max_moment\"].T).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "batch_size = 50000\n",
    "n_epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dipfit(dataset.n_chan,0)\n",
    "model = model.to(device)\n",
    "weight_localization = 0.5\n",
    "optimizer = optim.Adam(model.parameters(),3e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done in 3.00 seconds. \tTraining Loss: 0.035621805 \tValidation Loss: 0.016545072\n",
      "Epoch 2 done in 2.61 seconds. \tTraining Loss: 0.011539835 \tValidation Loss: 0.009305499\n",
      "Epoch 3 done in 2.61 seconds. \tTraining Loss: 0.008404497 \tValidation Loss: 0.007796114\n",
      "Epoch 4 done in 2.62 seconds. \tTraining Loss: 0.007392371 \tValidation Loss: 0.007084405\n",
      "Epoch 5 done in 2.61 seconds. \tTraining Loss: 0.006827597 \tValidation Loss: 0.006646983\n",
      "Epoch 6 done in 2.62 seconds. \tTraining Loss: 0.006461239 \tValidation Loss: 0.006351945\n",
      "Epoch 7 done in 2.63 seconds. \tTraining Loss: 0.006215000 \tValidation Loss: 0.006157367\n",
      "Epoch 8 done in 2.64 seconds. \tTraining Loss: 0.006036482 \tValidation Loss: 0.006009422\n",
      "Epoch 9 done in 2.63 seconds. \tTraining Loss: 0.005917590 \tValidation Loss: 0.005889713\n",
      "Epoch 10 done in 2.62 seconds. \tTraining Loss: 0.005820314 \tValidation Loss: 0.005822338\n",
      "Epoch 11 done in 2.63 seconds. \tTraining Loss: 0.005736969 \tValidation Loss: 0.005737299\n",
      "Epoch 12 done in 2.63 seconds. \tTraining Loss: 0.005672778 \tValidation Loss: 0.005706307\n",
      "Epoch 13 done in 2.62 seconds. \tTraining Loss: 0.005622051 \tValidation Loss: 0.005620054\n",
      "Epoch 14 done in 2.63 seconds. \tTraining Loss: 0.005564525 \tValidation Loss: 0.005591766\n",
      "Epoch 15 done in 2.62 seconds. \tTraining Loss: 0.005539502 \tValidation Loss: 0.005542465\n",
      "Epoch 16 done in 2.62 seconds. \tTraining Loss: 0.005489171 \tValidation Loss: 0.005510817\n",
      "Epoch 17 done in 2.61 seconds. \tTraining Loss: 0.005451206 \tValidation Loss: 0.005484880\n",
      "Epoch 18 done in 2.62 seconds. \tTraining Loss: 0.005423372 \tValidation Loss: 0.005464540\n",
      "Epoch 19 done in 2.62 seconds. \tTraining Loss: 0.005395534 \tValidation Loss: 0.005430431\n",
      "Epoch 20 done in 2.62 seconds. \tTraining Loss: 0.005365459 \tValidation Loss: 0.005406710\n",
      "Epoch 21 done in 2.63 seconds. \tTraining Loss: 0.005341860 \tValidation Loss: 0.005371704\n",
      "Epoch 22 done in 2.62 seconds. \tTraining Loss: 0.005313969 \tValidation Loss: 0.005342153\n",
      "Epoch 23 done in 2.61 seconds. \tTraining Loss: 0.005287420 \tValidation Loss: 0.005328448\n",
      "Epoch 24 done in 2.62 seconds. \tTraining Loss: 0.005269129 \tValidation Loss: 0.005314261\n",
      "Epoch 25 done in 2.63 seconds. \tTraining Loss: 0.005248930 \tValidation Loss: 0.005288549\n",
      "Epoch 26 done in 2.63 seconds. \tTraining Loss: 0.005226873 \tValidation Loss: 0.005271525\n",
      "Epoch 27 done in 2.62 seconds. \tTraining Loss: 0.005209355 \tValidation Loss: 0.005257402\n",
      "Epoch 28 done in 2.64 seconds. \tTraining Loss: 0.005191557 \tValidation Loss: 0.005233256\n",
      "Epoch 29 done in 2.62 seconds. \tTraining Loss: 0.005170733 \tValidation Loss: 0.005216422\n",
      "Epoch 30 done in 2.64 seconds. \tTraining Loss: 0.005154090 \tValidation Loss: 0.005208395\n",
      "Epoch 31 done in 2.64 seconds. \tTraining Loss: 0.005140147 \tValidation Loss: 0.005190924\n",
      "Epoch 32 done in 2.62 seconds. \tTraining Loss: 0.005122068 \tValidation Loss: 0.005171029\n",
      "Epoch 33 done in 2.63 seconds. \tTraining Loss: 0.005104916 \tValidation Loss: 0.005160856\n",
      "Epoch 34 done in 2.63 seconds. \tTraining Loss: 0.005091643 \tValidation Loss: 0.005151521\n",
      "Epoch 35 done in 2.62 seconds. \tTraining Loss: 0.005077814 \tValidation Loss: 0.005132694\n",
      "Epoch 36 done in 2.63 seconds. \tTraining Loss: 0.005061242 \tValidation Loss: 0.005118204\n",
      "Epoch 37 done in 2.64 seconds. \tTraining Loss: 0.005047216 \tValidation Loss: 0.005111710\n",
      "Epoch 38 done in 2.62 seconds. \tTraining Loss: 0.005036028 \tValidation Loss: 0.005101399\n",
      "Epoch 39 done in 2.63 seconds. \tTraining Loss: 0.005022962 \tValidation Loss: 0.005083118\n",
      "Epoch 40 done in 2.63 seconds. \tTraining Loss: 0.005007776 \tValidation Loss: 0.005070320\n",
      "Epoch 41 done in 2.64 seconds. \tTraining Loss: 0.004995309 \tValidation Loss: 0.005064746\n",
      "Epoch 42 done in 2.64 seconds. \tTraining Loss: 0.004985250 \tValidation Loss: 0.005055241\n",
      "Epoch 43 done in 2.64 seconds. \tTraining Loss: 0.004973520 \tValidation Loss: 0.005039266\n",
      "Epoch 44 done in 2.65 seconds. \tTraining Loss: 0.004959962 \tValidation Loss: 0.005027475\n",
      "Epoch 45 done in 2.63 seconds. \tTraining Loss: 0.004948225 \tValidation Loss: 0.005021561\n",
      "Epoch 46 done in 2.63 seconds. \tTraining Loss: 0.004938774 \tValidation Loss: 0.005015598\n",
      "Epoch 47 done in 2.63 seconds. \tTraining Loss: 0.004929255 \tValidation Loss: 0.005003468\n",
      "Epoch 48 done in 2.63 seconds. \tTraining Loss: 0.004917601 \tValidation Loss: 0.004990964\n",
      "Epoch 49 done in 2.63 seconds. \tTraining Loss: 0.004906100 \tValidation Loss: 0.004982936\n",
      "Epoch 50 done in 2.63 seconds. \tTraining Loss: 0.004896297 \tValidation Loss: 0.004978410\n",
      "Epoch 51 done in 2.63 seconds. \tTraining Loss: 0.004887754 \tValidation Loss: 0.004972129\n",
      "Epoch 52 done in 2.63 seconds. \tTraining Loss: 0.004878763 \tValidation Loss: 0.004961671\n",
      "Epoch 53 done in 2.63 seconds. \tTraining Loss: 0.004868603 \tValidation Loss: 0.004951223\n",
      "Epoch 54 done in 2.63 seconds. \tTraining Loss: 0.004858679 \tValidation Loss: 0.004944196\n",
      "Epoch 55 done in 2.63 seconds. \tTraining Loss: 0.004850017 \tValidation Loss: 0.004939595\n",
      "Epoch 56 done in 2.63 seconds. \tTraining Loss: 0.004842138 \tValidation Loss: 0.004934017\n",
      "Epoch 57 done in 2.63 seconds. \tTraining Loss: 0.004834296 \tValidation Loss: 0.004926297\n",
      "Epoch 58 done in 2.64 seconds. \tTraining Loss: 0.004826018 \tValidation Loss: 0.004918184\n",
      "Epoch 59 done in 2.65 seconds. \tTraining Loss: 0.004817808 \tValidation Loss: 0.004911426\n",
      "Epoch 60 done in 2.64 seconds. \tTraining Loss: 0.004810011 \tValidation Loss: 0.004905829\n",
      "Epoch 61 done in 2.63 seconds. \tTraining Loss: 0.004802660 \tValidation Loss: 0.004900622\n",
      "Epoch 62 done in 2.63 seconds. \tTraining Loss: 0.004795659 \tValidation Loss: 0.004895770\n",
      "Epoch 63 done in 2.63 seconds. \tTraining Loss: 0.004788835 \tValidation Loss: 0.004890506\n",
      "Epoch 64 done in 2.64 seconds. \tTraining Loss: 0.004782136 \tValidation Loss: 0.004885170\n",
      "Epoch 65 done in 2.63 seconds. \tTraining Loss: 0.004775482 \tValidation Loss: 0.004879601\n",
      "Epoch 66 done in 2.63 seconds. \tTraining Loss: 0.004768933 \tValidation Loss: 0.004874166\n",
      "Epoch 67 done in 2.63 seconds. \tTraining Loss: 0.004762532 \tValidation Loss: 0.004869041\n",
      "Epoch 68 done in 2.63 seconds. \tTraining Loss: 0.004756294 \tValidation Loss: 0.004864085\n",
      "Epoch 69 done in 2.64 seconds. \tTraining Loss: 0.004750151 \tValidation Loss: 0.004859219\n",
      "Epoch 70 done in 2.64 seconds. \tTraining Loss: 0.004744195 \tValidation Loss: 0.004854765\n",
      "Epoch 71 done in 2.64 seconds. \tTraining Loss: 0.004738256 \tValidation Loss: 0.004850643\n",
      "Epoch 72 done in 2.64 seconds. \tTraining Loss: 0.004732369 \tValidation Loss: 0.004846567\n",
      "Epoch 73 done in 2.64 seconds. \tTraining Loss: 0.004726614 \tValidation Loss: 0.004842961\n",
      "Epoch 74 done in 2.64 seconds. \tTraining Loss: 0.004721050 \tValidation Loss: 0.004838919\n",
      "Epoch 75 done in 2.64 seconds. \tTraining Loss: 0.004715440 \tValidation Loss: 0.004834397\n",
      "75 epochs ready in 197.608 seconds. Minimum validation loss: 0.004834\n",
      "Train batch time: 0.10168 ± 0.00219 seconds\n",
      "Valid batch time: 0.06852 ± 0.00095 seconds\n"
     ]
    }
   ],
   "source": [
    "model, train_loss, valid_loss = train(model,dataset,n_epochs,batch_size,device,optimizer,weight_localization,\"best_model.pt\",\n",
    "     min_location,max_location,min_moment,max_moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: \n",
      "NN: 0.004625\n",
      "LM: 0.011570\n",
      "\n",
      "Localization error: \n",
      "NN: 1.115 cm\n",
      "LM: 1.071 cm\n"
     ]
    }
   ],
   "source": [
    "# Calculate test loss for the network\n",
    "x = torch.from_numpy(dataset.data_test[\"fields\"]).to(device)\n",
    "y = torch.from_numpy(dataset.data_test[\"dipoles\"]).to(device)\n",
    "output = model(x)\n",
    "test_loss_nn = weighted_mse(normalize_dipole(output,dataset.data_test,device,min_location,max_location,min_moment,max_moment), \n",
    "                 normalize_dipole(y,dataset.data_test,device,min_location,max_location,min_moment,max_moment), weight_localization).item()\n",
    "\n",
    "# Test loss for Levenberg-Marquadt\n",
    "x = torch.from_numpy(dataset.data_test[\"dipoles_estimated\"]).to(device)\n",
    "y = torch.from_numpy(dataset.data_test[\"dipoles\"]).to(device).squeeze()\n",
    "test_loss_lm = weighted_mse(normalize_dipole(x,dataset.data_test,device,min_location,max_location,min_moment,max_moment), \n",
    "                 normalize_dipole(y,dataset.data_test,device,min_location,max_location,min_moment,max_moment), weight_localization)\n",
    "print(f\"Test loss: \\nNN: {test_loss_nn:.6f}\\nLM: {test_loss_lm:.6f}\")\n",
    "\n",
    "# Localization errors\n",
    "loc_error_nn = np.mean(get_localization_error(output.to(\"cpu\").detach().numpy(),dataset.data_test[\"dipoles\"]))\n",
    "loc_error_lm = np.mean(get_localization_error(dataset.data_test[\"dipoles_estimated\"],dataset.data_test[\"dipoles\"]))\n",
    "print(f\"\\nLocalization error: \\nNN: {loc_error_nn:.3f} cm\\nLM: {loc_error_lm:.3f} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
