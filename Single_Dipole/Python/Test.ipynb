{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Using GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "from misc import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# First we should load the .mat file\n",
    "data_dir = \"C:/Users/Mircea/Google Drive/Data/nn-dipole-fitting/\"\n",
    "path_list = [each.replace(\"\\\\\",\"/\") for each in glob(data_dir + \"Dataset SNR*.mat\")]\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using\",torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data if not already in memory\n",
    "if \"data_train\" not in globals():\n",
    "    dataset = dataset_from_mat(path_list[1])\n",
    "\n",
    "min_location = torch.from_numpy(dataset.data_train[\"min_location\"].T).to(device)\n",
    "max_location = torch.from_numpy(dataset.data_train[\"max_location\"].T).to(device)\n",
    "min_moment = torch.from_numpy(dataset.data_train[\"min_moment\"].T).to(device)\n",
    "max_moment = torch.from_numpy(dataset.data_train[\"max_moment\"].T).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "batch_size = 50000\n",
    "n_epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dipfit(dataset.n_chan,0)\n",
    "model = model.to(device)\n",
    "weight_localization = 0.5\n",
    "optimizer = optim.Adam(model.parameters(),3e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done in 2.56 seconds. \tTraining Loss: 0.055436768 \tValidation Loss: 0.037539851\n",
      "Epoch 2 done in 1.98 seconds. \tTraining Loss: 0.031636956 \tValidation Loss: 0.026768494\n",
      "Epoch 3 done in 1.95 seconds. \tTraining Loss: 0.022559148 \tValidation Loss: 0.018546814\n",
      "Epoch 4 done in 1.95 seconds. \tTraining Loss: 0.016517937 \tValidation Loss: 0.015136175\n",
      "Epoch 5 done in 1.93 seconds. \tTraining Loss: 0.014614536 \tValidation Loss: 0.014159390\n",
      "Epoch 6 done in 1.94 seconds. \tTraining Loss: 0.013849325 \tValidation Loss: 0.013584592\n",
      "Epoch 7 done in 1.95 seconds. \tTraining Loss: 0.013348309 \tValidation Loss: 0.013153106\n",
      "Epoch 8 done in 1.95 seconds. \tTraining Loss: 0.012950884 \tValidation Loss: 0.012795813\n",
      "Epoch 9 done in 1.96 seconds. \tTraining Loss: 0.012619412 \tValidation Loss: 0.012496774\n",
      "Epoch 10 done in 1.97 seconds. \tTraining Loss: 0.012339418 \tValidation Loss: 0.012243120\n",
      "Epoch 11 done in 1.95 seconds. \tTraining Loss: 0.012100747 \tValidation Loss: 0.012026830\n",
      "Epoch 12 done in 1.96 seconds. \tTraining Loss: 0.011897905 \tValidation Loss: 0.011840831\n",
      "Epoch 13 done in 1.96 seconds. \tTraining Loss: 0.011724397 \tValidation Loss: 0.011681382\n",
      "Epoch 14 done in 1.94 seconds. \tTraining Loss: 0.011574573 \tValidation Loss: 0.011543780\n",
      "Epoch 15 done in 1.95 seconds. \tTraining Loss: 0.011443800 \tValidation Loss: 0.011423278\n",
      "Epoch 16 done in 1.94 seconds. \tTraining Loss: 0.011328154 \tValidation Loss: 0.011316312\n",
      "Epoch 17 done in 2.45 seconds. \tTraining Loss: 0.011224725 \tValidation Loss: 0.011220224\n",
      "Epoch 18 done in 1.96 seconds. \tTraining Loss: 0.011131202 \tValidation Loss: 0.011132830\n",
      "Epoch 19 done in 1.95 seconds. \tTraining Loss: 0.011045663 \tValidation Loss: 0.011052570\n",
      "Epoch 20 done in 1.95 seconds. \tTraining Loss: 0.010966683 \tValidation Loss: 0.010977887\n",
      "Epoch 21 done in 1.95 seconds. \tTraining Loss: 0.010893135 \tValidation Loss: 0.010908435\n",
      "Epoch 22 done in 1.95 seconds. \tTraining Loss: 0.010824284 \tValidation Loss: 0.010843330\n",
      "Epoch 23 done in 1.94 seconds. \tTraining Loss: 0.010759466 \tValidation Loss: 0.010781985\n",
      "Epoch 24 done in 1.98 seconds. \tTraining Loss: 0.010698201 \tValidation Loss: 0.010723963\n",
      "Epoch 25 done in 1.99 seconds. \tTraining Loss: 0.010640049 \tValidation Loss: 0.010668973\n",
      "Epoch 26 done in 1.96 seconds. \tTraining Loss: 0.010584669 \tValidation Loss: 0.010616792\n",
      "Epoch 27 done in 1.95 seconds. \tTraining Loss: 0.010532078 \tValidation Loss: 0.010567464\n",
      "Epoch 28 done in 1.96 seconds. \tTraining Loss: 0.010482264 \tValidation Loss: 0.010520771\n",
      "Epoch 29 done in 1.93 seconds. \tTraining Loss: 0.010435001 \tValidation Loss: 0.010476653\n",
      "Epoch 30 done in 1.94 seconds. \tTraining Loss: 0.010390275 \tValidation Loss: 0.010434987\n",
      "Epoch 31 done in 1.93 seconds. \tTraining Loss: 0.010347832 \tValidation Loss: 0.010395638\n",
      "Epoch 32 done in 1.95 seconds. \tTraining Loss: 0.010307400 \tValidation Loss: 0.010358347\n",
      "Epoch 33 done in 1.94 seconds. \tTraining Loss: 0.010268991 \tValidation Loss: 0.010323205\n",
      "Epoch 34 done in 1.92 seconds. \tTraining Loss: 0.010232716 \tValidation Loss: 0.010290268\n",
      "Epoch 35 done in 1.96 seconds. \tTraining Loss: 0.010198515 \tValidation Loss: 0.010259164\n",
      "Epoch 36 done in 2.08 seconds. \tTraining Loss: 0.010166134 \tValidation Loss: 0.010229568\n",
      "Epoch 37 done in 2.09 seconds. \tTraining Loss: 0.010135119 \tValidation Loss: 0.010201716\n",
      "Epoch 38 done in 1.98 seconds. \tTraining Loss: 0.010105661 \tValidation Loss: 0.010174925\n",
      "Epoch 39 done in 1.97 seconds. \tTraining Loss: 0.010077663 \tValidation Loss: 0.010149611\n",
      "Epoch 40 done in 1.97 seconds. \tTraining Loss: 0.010051000 \tValidation Loss: 0.010125464\n",
      "Epoch 41 done in 1.96 seconds. \tTraining Loss: 0.010025536 \tValidation Loss: 0.010102526\n",
      "Epoch 42 done in 1.97 seconds. \tTraining Loss: 0.010001212 \tValidation Loss: 0.010080704\n",
      "Epoch 43 done in 1.98 seconds. \tTraining Loss: 0.009977851 \tValidation Loss: 0.010059503\n",
      "Epoch 44 done in 1.96 seconds. \tTraining Loss: 0.009955272 \tValidation Loss: 0.010039199\n",
      "Epoch 45 done in 1.95 seconds. \tTraining Loss: 0.009933561 \tValidation Loss: 0.010019749\n",
      "Epoch 46 done in 1.98 seconds. \tTraining Loss: 0.009912570 \tValidation Loss: 0.010000851\n",
      "Epoch 47 done in 1.96 seconds. \tTraining Loss: 0.009892157 \tValidation Loss: 0.009982519\n",
      "Epoch 48 done in 1.98 seconds. \tTraining Loss: 0.009872296 \tValidation Loss: 0.009964832\n",
      "Epoch 49 done in 1.96 seconds. \tTraining Loss: 0.009853051 \tValidation Loss: 0.009947668\n",
      "Epoch 50 done in 1.98 seconds. \tTraining Loss: 0.009834294 \tValidation Loss: 0.009930824\n",
      "Epoch 51 done in 1.98 seconds. \tTraining Loss: 0.009815972 \tValidation Loss: 0.009914504\n",
      "Epoch 52 done in 1.96 seconds. \tTraining Loss: 0.009798208 \tValidation Loss: 0.009898674\n",
      "Epoch 53 done in 1.96 seconds. \tTraining Loss: 0.009780772 \tValidation Loss: 0.009883025\n",
      "Epoch 54 done in 1.96 seconds. \tTraining Loss: 0.009763748 \tValidation Loss: 0.009867749\n",
      "Epoch 55 done in 1.99 seconds. \tTraining Loss: 0.009747086 \tValidation Loss: 0.009853039\n",
      "Epoch 56 done in 1.97 seconds. \tTraining Loss: 0.009730837 \tValidation Loss: 0.009838762\n",
      "Epoch 57 done in 1.99 seconds. \tTraining Loss: 0.009714906 \tValidation Loss: 0.009824810\n",
      "Epoch 58 done in 1.98 seconds. \tTraining Loss: 0.009699287 \tValidation Loss: 0.009811186\n",
      "Epoch 59 done in 1.97 seconds. \tTraining Loss: 0.009683973 \tValidation Loss: 0.009798178\n",
      "Epoch 60 done in 1.93 seconds. \tTraining Loss: 0.009668987 \tValidation Loss: 0.009785451\n",
      "Epoch 61 done in 1.97 seconds. \tTraining Loss: 0.009654342 \tValidation Loss: 0.009773033\n",
      "Epoch 62 done in 1.95 seconds. \tTraining Loss: 0.009639988 \tValidation Loss: 0.009760881\n",
      "Epoch 63 done in 1.94 seconds. \tTraining Loss: 0.009625879 \tValidation Loss: 0.009749088\n",
      "Epoch 64 done in 1.96 seconds. \tTraining Loss: 0.009612050 \tValidation Loss: 0.009737487\n",
      "Epoch 65 done in 1.96 seconds. \tTraining Loss: 0.009598471 \tValidation Loss: 0.009726218\n",
      "Epoch 66 done in 1.97 seconds. \tTraining Loss: 0.009585165 \tValidation Loss: 0.009715203\n",
      "Epoch 67 done in 1.96 seconds. \tTraining Loss: 0.009572080 \tValidation Loss: 0.009704284\n",
      "Epoch 68 done in 1.95 seconds. \tTraining Loss: 0.009559224 \tValidation Loss: 0.009693713\n",
      "Epoch 69 done in 1.98 seconds. \tTraining Loss: 0.009546535 \tValidation Loss: 0.009683324\n",
      "Epoch 70 done in 1.97 seconds. \tTraining Loss: 0.009534060 \tValidation Loss: 0.009673140\n",
      "Epoch 71 done in 1.96 seconds. \tTraining Loss: 0.009521782 \tValidation Loss: 0.009663133\n",
      "Epoch 72 done in 1.93 seconds. \tTraining Loss: 0.009509737 \tValidation Loss: 0.009653426\n",
      "Epoch 73 done in 1.99 seconds. \tTraining Loss: 0.009497934 \tValidation Loss: 0.009643964\n",
      "Epoch 74 done in 1.97 seconds. \tTraining Loss: 0.009486262 \tValidation Loss: 0.009634551\n",
      "Epoch 75 done in 1.96 seconds. \tTraining Loss: 0.009474749 \tValidation Loss: 0.009625250\n",
      "75 epochs ready in 148.302 seconds. Minimum validation loss: 0.009625\n",
      "Train batch time: 0.06091 ± 0.00340 seconds\n",
      "Valid batch time: 0.03347 ± 0.00190 seconds\n"
     ]
    }
   ],
   "source": [
    "model, train_loss, valid_loss = train(model,dataset,n_epochs,batch_size,device,optimizer,weight_localization,\"best_model.pt\",\n",
    "     min_location,max_location,min_moment,max_moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: \n",
      "NN: 0.009794\n",
      "LM: 0.025418\n",
      "\n",
      "Localization error: \n",
      "NN: 2.195 cm\n",
      "LM: 2.342 cm\n"
     ]
    }
   ],
   "source": [
    "# Calculate test loss for the network\n",
    "x = torch.from_numpy(dataset.data_test[\"fields\"]).to(device)\n",
    "y = torch.from_numpy(dataset.data_test[\"dipoles\"]).to(device)\n",
    "output = model(x)\n",
    "test_loss_nn = weighted_mse(normalize_dipole(output,dataset.data_test,device,min_location,max_location,min_moment,max_moment), \n",
    "                 normalize_dipole(y,dataset.data_test,device,min_location,max_location,min_moment,max_moment), weight_localization).item()\n",
    "\n",
    "# Test loss for Levenberg-Marquadt\n",
    "x = torch.from_numpy(dataset.data_test[\"dipoles_estimated\"]).to(device)\n",
    "y = torch.from_numpy(dataset.data_test[\"dipoles\"]).to(device).squeeze()\n",
    "test_loss_lm = weighted_mse(normalize_dipole(x,dataset.data_test,device,min_location,max_location,min_moment,max_moment), \n",
    "                 normalize_dipole(y,dataset.data_test,device,min_location,max_location,min_moment,max_moment), weight_localization)\n",
    "print(f\"Test loss: \\nNN: {test_loss_nn:.6f}\\nLM: {test_loss_lm:.6f}\")\n",
    "\n",
    "# Localization errors\n",
    "loc_error_nn = np.mean(get_localization_error(output.to(\"cpu\").detach().numpy(),dataset.data_test[\"dipoles\"]))\n",
    "loc_error_lm = np.mean(get_localization_error(dataset.data_test[\"dipoles_estimated\"],dataset.data_test[\"dipoles\"]))\n",
    "print(f\"\\nLocalization error: \\nNN: {loc_error_nn:.3f} cm\\nLM: {loc_error_lm:.3f} cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
